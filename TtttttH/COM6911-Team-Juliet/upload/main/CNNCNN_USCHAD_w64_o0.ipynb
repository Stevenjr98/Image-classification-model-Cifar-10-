{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-USCHAD_w64_o0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cFRbZHfZtoGedca1sD2XgVvDAgnL0IPq",
      "authorship_tag": "ABX9TyNNRKKf9GnLfxmNF7GS7Lu5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevenjr98/Image-classification-model-Cifar-10-/blob/main/TtttttH/COM6911-Team-Juliet/upload/main/CNNCNN_USCHAD_w64_o0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HusfROkE-F_L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "usc_raw_data = pd.read_csv('/content/drive/MyDrive/Industrial Team Project/USCHAD_rawdata.csv')"
      ],
      "metadata": {
        "id": "TXx_zqAK-Qri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only features and label.\n",
        "usc_unprocessed = usc_raw_data[['acc_x','acc_y','acc_z','gyro_x','gyro_y','gyro_z','label']]"
      ],
      "metadata": {
        "id": "nSO_HPHS-VlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# window_size: size of time window\n",
        "# step: overlapping\n",
        "# data: dataset\n",
        "def time_windows(window_size,overlapping,data):\n",
        "  sigmentation_data_temp = []\n",
        "  sigmentation_data = []\n",
        "  sigmentation_label = []\n",
        "  for i in range(0,len(data),overlapping):\n",
        "    acc_x = data['acc_x'].values[i:i+window_size]\n",
        "    acc_y = data['acc_y'].values[i:i+window_size]\n",
        "    acc_z = data['acc_z'].values[i:i+window_size]\n",
        "    gyro_x = data['gyro_x'].values[i:i+window_size]\n",
        "    gyro_y = data['gyro_y'].values[i:i+window_size]\n",
        "    gyro_z = data['gyro_z'].values[i:i+window_size]\n",
        "    total_label = data['label'].values[i:i+window_size]\n",
        "    label = Counter(total_label).most_common()[0][0]\n",
        "    sigmentation_data_temp.append([acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z])\n",
        "    sigmentation_arr = np.asarray(sigmentation_data_temp)\n",
        "    sig_size = sigmentation_arr.shape\n",
        "    if sig_size[2] == window_size:\n",
        "      sigmentation_arr.reshape(window_size,6)\n",
        "      sigmentation_data.append(sigmentation_arr)\n",
        "      sigmentation_label.append(label)\n",
        "      sigmentation_data_temp = []\n",
        "    else:\n",
        "      sigmentation_data_temp = []\n",
        "\n",
        "  sigmentation_data_arr = np.asarray(sigmentation_data)\n",
        "  sigmentation_label_arr = np.asarray(sigmentation_label)\n",
        "\n",
        "  return sigmentation_data_arr,sigmentation_label_arr"
      ],
      "metadata": {
        "id": "R9Z_F0pg-bZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here use semi-non-overlapping\n",
        "# signal segmentation and relevant labels\n",
        "uci_readings,uci_labels = time_windows(64,64,usc_unprocessed)"
      ],
      "metadata": {
        "id": "2bMQvh6E-c2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in the model, requires 0-n label so make labels from 1-12 into 0-11\n",
        "uci_labels = uci_labels-1"
      ],
      "metadata": {
        "id": "ePE7zPTM-e3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use train_test_split to generate train,val and test data\n",
        "x_train_non_overlapping,x_val_test_non_overlapping,y_train_non_overlapping,y_val_test_non_overlapping = train_test_split(uci_readings,uci_labels,test_size = 0.3)\n",
        "x_val_non_overlapping,x_test_non_overlapping,y_val_non_overlapping,y_test_non_overlapping = train_test_split(x_val_test_non_overlapping,y_val_test_non_overlapping,test_size = 0.3 )"
      ],
      "metadata": {
        "id": "vg88as_i-gUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_train_non_overlapping).to(torch.float32),torch.from_numpy(y_train_non_overlapping).to(torch.float32))\n",
        "val_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_val_non_overlapping).to(torch.float32),torch.from_numpy(y_val_non_overlapping).to(torch.float32))\n",
        "test_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_test_non_overlapping).to(torch.float32),torch.from_numpy(y_test_non_overlapping).to(torch.float32))"
      ],
      "metadata": {
        "id": "jo2aTiZeBQfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader generation\n",
        "train_loader_non_overlapping = data.DataLoader(dataset = train_dataset_non_overlapping,batch_size = 64,shuffle = True)\n",
        "val_loader_non_overlapping = data.DataLoader(dataset = val_dataset_non_overlapping,batch_size = 64,shuffle = True)\n",
        "test_loader_non_overlapping = data.DataLoader(dataset = test_dataset_non_overlapping,batch_size = 64,shuffle = False)"
      ],
      "metadata": {
        "id": "j3-s6SCqBVWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # now define a class of CNN model\n",
        "class CNN_w64_o0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_w64_o0, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "             nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(32),\n",
        "             nn.MaxPool2d(2,2))\n",
        "    self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU()\n",
        "    )\n",
        "    self.drop_out = nn.Dropout()\n",
        "    self.fc1 = nn.Linear(1536, 512)\n",
        "    self.fc3 = nn.Linear(512,12)\n",
        "  def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "        \n",
        "model_w64_o0 = CNN_w64_o0().to(device)"
      ],
      "metadata": {
        "id": "R2h00Zb4B1JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 50\n",
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_w64_o0.parameters(),lr=lr, weight_decay=0.0001,momentum = 0.8)"
      ],
      "metadata": {
        "id": "iaPCt_FmCE3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "loss_list = []\n",
        "for epoch in range(epoches):\n",
        "    acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_num = 0\n",
        "    runtime_loss = 0\n",
        "    for (imgs,labels) in train_loader_non_overlapping:\n",
        "        imgs = imgs.reshape(len(imgs),1,24,16)     \n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_w64_o0(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        runtime_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss_num+=1\n",
        "    acc = 100 * correct / total\n",
        "    epoch_loss = runtime_loss / loss_num\n",
        "    loss_list.append(epoch_loss)\n",
        "    loss_num = 0\n",
        "    print(\"Epoch: \",epoch+1, \"accuracy: \", acc,' %',\"Loss: \",epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GRZwjxZCH5i",
        "outputId": "56c64a9a-1f1a-4460-d222-24fa0bccc0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 accuracy:  36.48375968235371  % Loss:  1.7068384419855605\n",
            "Epoch:  2 accuracy:  48.31087678187854  % Loss:  1.3641420347527011\n",
            "Epoch:  3 accuracy:  55.718284189285946  % Loss:  1.2073183554125924\n",
            "Epoch:  4 accuracy:  62.735142875740415  % Loss:  1.0359612728107\n",
            "Epoch:  5 accuracy:  68.77562975981253  % Loss:  0.8516914133222584\n",
            "Epoch:  6 accuracy:  71.8023823471978  % Loss:  0.7662669888033441\n",
            "Epoch:  7 accuracy:  73.40037753043025  % Loss:  0.7174253059152258\n",
            "Epoch:  8 accuracy:  74.61107856538436  % Loss:  0.6794848347280229\n",
            "Epoch:  9 accuracy:  75.85757989975916  % Loss:  0.653604200377038\n",
            "Epoch:  10 accuracy:  76.65169563236347  % Loss:  0.6348572677609331\n",
            "Epoch:  11 accuracy:  77.4555750829916  % Loss:  0.6081153736788617\n",
            "Epoch:  12 accuracy:  77.59226713532513  % Loss:  0.6097452607075539\n",
            "Epoch:  13 accuracy:  78.55236607433444  % Loss:  0.5755556180546536\n",
            "Epoch:  14 accuracy:  79.04706112087483  % Loss:  0.5581824177887732\n",
            "Epoch:  15 accuracy:  79.32044522554189  % Loss:  0.5514434892025906\n",
            "Epoch:  16 accuracy:  80.1178155308208  % Loss:  0.5350285507661141\n",
            "Epoch:  17 accuracy:  80.39119963548787  % Loss:  0.5219127179555239\n",
            "Epoch:  18 accuracy:  80.64180173143266  % Loss:  0.5157749527705187\n",
            "Epoch:  19 accuracy:  80.87938553667904  % Loss:  0.5030855052560382\n",
            "Epoch:  20 accuracy:  81.2406431035605  % Loss:  0.49865752477160113\n",
            "Epoch:  21 accuracy:  81.53680921694982  % Loss:  0.4875840271461035\n",
            "Epoch:  22 accuracy:  82.12588687105384  % Loss:  0.47398243054530725\n",
            "Epoch:  23 accuracy:  81.73208357742628  % Loss:  0.47645606308122185\n",
            "Epoch:  24 accuracy:  82.37974353967324  % Loss:  0.4635136192761315\n",
            "Epoch:  25 accuracy:  82.66614593503873  % Loss:  0.45212810113251584\n",
            "Epoch:  26 accuracy:  82.59454533619736  % Loss:  0.4504659461814004\n",
            "Epoch:  27 accuracy:  82.79307426934844  % Loss:  0.4447317867231964\n",
            "Epoch:  28 accuracy:  83.02089435657098  % Loss:  0.4390153997963035\n",
            "Epoch:  29 accuracy:  83.21291414437285  % Loss:  0.43537690395996625\n",
            "Epoch:  30 accuracy:  83.55138970253206  % Loss:  0.43303258357697366\n",
            "Epoch:  31 accuracy:  81.31224370240187  % Loss:  0.4857447275314906\n",
            "Epoch:  32 accuracy:  83.59695371997657  % Loss:  0.4257552080367558\n",
            "Epoch:  33 accuracy:  83.85406496127058  % Loss:  0.41620186336818704\n",
            "Epoch:  34 accuracy:  84.15999479268372  % Loss:  0.4097847949070643\n",
            "Epoch:  35 accuracy:  84.04933932174706  % Loss:  0.4075438143867465\n",
            "Epoch:  36 accuracy:  84.2381045368743  % Loss:  0.40745993128933183\n",
            "Epoch:  37 accuracy:  84.34876000781098  % Loss:  0.3983352525380446\n",
            "Epoch:  38 accuracy:  84.5668163770097  % Loss:  0.3963121031401311\n",
            "Epoch:  39 accuracy:  84.58308924038273  % Loss:  0.3919091948972175\n",
            "Epoch:  40 accuracy:  84.51148864154136  % Loss:  0.39480512615548846\n",
            "Epoch:  41 accuracy:  84.89878278981969  % Loss:  0.38391006212844175\n",
            "Epoch:  42 accuracy:  85.2340037753043  % Loss:  0.3779198572256461\n",
            "Epoch:  43 accuracy:  85.08103885959774  % Loss:  0.37928073036943305\n",
            "Epoch:  44 accuracy:  84.77185445551  % Loss:  0.384447753553331\n",
            "Epoch:  45 accuracy:  85.19494890320901  % Loss:  0.3706369717254956\n",
            "Epoch:  46 accuracy:  85.50087873462215  % Loss:  0.36278603084989497\n",
            "Epoch:  47 accuracy:  85.72544424917008  % Loss:  0.35884634199360554\n",
            "Epoch:  48 accuracy:  85.97279177244027  % Loss:  0.35601379406365435\n",
            "Epoch:  49 accuracy:  85.52040617066979  % Loss:  0.3575918380473111\n",
            "Epoch:  50 accuracy:  85.51389702532057  % Loss:  0.3622708481246617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "correct_test = 0\n",
        "\n",
        "total_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for (imgs_test,labels_test) in test_loader_non_overlapping:\n",
        "\n",
        "    imgs_test = imgs_test.reshape(len(imgs_test),1,24,16)\n",
        "\n",
        "    imgs_test = imgs_test.to(device)\n",
        "\n",
        "    labels_test = labels_test.type(torch.LongTensor)\n",
        "\n",
        "    labels_test = labels_test.to(device)\n",
        "\n",
        "    outputs_test = model_w64_o0(imgs_test)\n",
        "\n",
        "    labels_test = labels_test.reshape(labels_test.shape[0],)\n",
        "\n",
        "    predicted_test = torch.max(outputs_test.data,1)[1]\n",
        "      \n",
        "    total_test += labels_test.size(0)\n",
        "      \n",
        "    correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100*correct_test/total_test\n",
        "\n",
        "print('Test accuracy is: ',test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRonVsJnCPiv",
        "outputId": "c2aae6a7-5207-49c9-fbbb-e1631a12e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is:  80.25816249050874\n"
          ]
        }
      ]
    }
  ]
}